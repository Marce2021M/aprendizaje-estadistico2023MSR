#+TITLE: EST-25134: Aprendizaje Estadístico
#+AUTHOR: Prof. Alfredo Garbuno Iñigo
#+EMAIL:  agarbuno@itam.mx
#+DATE: ~Modelos de ensamble~
#+STARTUP: showall
:REVEAL_PROPERTIES:
# Template uses org export with export option <R B>
# Alternatives: use with citeproc
#+LANGUAGE: es
#+OPTIONS: num:nil toc:nil timestamp:nil
#+REVEAL_REVEAL_JS_VERSION: 4
#+REVEAL_MATHJAX_URL: https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js
#+REVEAL_THEME: night
#+REVEAL_SLIDE_NUMBER: t
#+REVEAL_HEAD_PREAMBLE: <meta name="description" content="Aprendizaje">
#+REVEAL_INIT_OPTIONS: width:1600, height:900, margin:.2
#+REVEAL_EXTRA_CSS: ./mods.css
#+REVEAL_PLUGINS: (notes)
:END:
#+PROPERTY: header-args:R :session ensamble :exports both :results output org :tangle ../rscripts/09-ensamble.R :mkdirp yes :dir ../ :eval never
#+EXCLUDE_TAGS: toc latex noexport

#+BEGIN_NOTES
*Profesor*: Alfredo Garbuno Iñigo | Primavera, 2023 | Modelos en ensamble.\\
*Objetivo*: En esta sección estudiaremos una forma de incorporar varios modelos
 para crear un modelo predictivo mas fuerte que un modelo individual. La
 estrategia está basada en una técnica de remuestreo que ya hemos estudiado
 previamente.\\
*Lectura recomendada*: Sección 8.2 de citet:James2021. Capítulo 15 de
 citet:Hastie2009c. Capítulo 5 (/bagging/) y 7 (/random forest/) de
 citet:Greenwell2022.
#+END_NOTES

#+begin_src R :exports none :results none
  ## Setup ---------------------------------------------------------------------
  library(tidyverse)
  library(patchwork)
  library(scales)

  ## Cambia el default del tamaño de fuente 
  theme_set(theme_linedraw(base_size = 20))

  ## Cambia el número de decimales para mostrar
  options(digits = 4)
  ## Problemas con mi consola en Emacs
  options(pillar.subtle = FALSE)
  options(rlang_backtrace_on_error = "none")
  options(crayon.enabled = FALSE)

  ## Para el tema de ggplot
  sin_lineas <- theme(panel.grid.major = element_blank(),
                      panel.grid.minor = element_blank())
  color.itam  <- c("#00362b","#004a3b", "#00503f", "#006953", "#008367", "#009c7b", "#00b68f", NA)

  sin_leyenda <- theme(legend.position = "none")
  sin_ejes <- theme(axis.ticks = element_blank(), axis.text = element_blank())
#+end_src


#+begin_src R :exports none :results none 
  library(tidymodels)
#+end_src


* Contenido                                                             :toc:
:PROPERTIES:
:TOC:      :include all  :ignore this :depth 3
:END:
:CONTENTS:
- [[#introducción][Introducción]]
- [[#remuestreo-o-bootstrap][Remuestreo o bootstrap]]
  - [[#importante][Importante:]]
  - [[#para-pensar][Para pensar:]]
- [[#bootstrapped-aggregation-bagging][Bootstrapped aggregation: Bagging]]
  - [[#en-problemas-de-clasificación][En problemas de clasificación]]
  - [[#error-de-generalización][Error de generalización]]
  - [[#observaciones][Observaciones]]
  - [[#bagging-regresión-y-mse][Bagging, regresión y MSE]]
  - [[#bagging-y-clasificación][Bagging y clasificación]]
    - [[#bagging-y-clasificadores][Bagging y clasificadores:]]
    - [[#bagging-y-la-sabiduría-de-las-masas][Bagging y la sabiduría de las masas:]]
  - [[#observaciones][Observaciones]]
- [[#aplicación-misiones-de-astronautas][Aplicación: Misiones de astronautas]]
  - [[#proceso-de-modelado][Proceso de modelado]]
  - [[#ajuste-de-bagging-con-árboles-de-clasificación][Ajuste de bagging con árboles de clasificación]]
- [[#bosques-aleatorios][Bosques aleatorios]]
  - [[#motivación][Motivación]]
  - [[#sobre-ajuste][Sobre-ajuste]]
  - [[#análisis-de-ajuste][Análisis de ajuste]]
- [[#aplicación-predicción-de-precios-ikea][Aplicación: Predicción de precios IKEA]]
  - [[#preparación-de-datos][Preparación de datos]]
  - [[#especificación-del-modelo][Especificación del modelo]]
  - [[#post-procesando-el-bosque][Post-procesando el bosque]]
  - [[#post-procesamiento-predictivo][Post-procesamiento predictivo]]
- [[#conclusiones][Conclusiones]]
:END:

* Introducción 

Anteriormente, vimos los modelos predictivos basados en ~árboles de decisión~ (regresión y clasificación). En esta sección del curso estudiaremos ~distintas estrategias~ para combinarlos para obtener un mejor modelo predictivo al costo de ~interpretabilidad~. Algunos de estos modelos continúan representando el estado del arte en competencias como [[https://www.kaggle.com/][Kaggle]] para ~datos tabulares~.


#+DOWNLOADED: screenshot @ 2022-04-13 15:27:21
#+caption: Algoritmos que tienden a quedar en los primeros lugares en las competencias de Kaggle. Tomado de [[https://www.kaggle.com/code/msjgriffiths/r-what-algorithms-are-most-successful-on-kaggle/report?scriptVersionId=0][aquí]]. 
#+attr_latex: :width .65\linewidth
#+attr_html: :width 400 :align center
[[file:images/20220413-152721_screenshot.png]]


#+REVEAL: split
De igual manera se han publicado algunos reportes donde se confirma que en particular para ~datos tabulares~ modelos de ensamble basados en árboles tienen mejor capacidad predictiva.

#+DOWNLOADED: screenshot @ 2023-03-29 21:22:28
#+attr_html: :width 1200 :align center
[[file:images/20230329-212228_screenshot.png]]
#+DOWNLOADED: screenshot @ 2023-03-29 21:21:02
#+attr_html: :width 1200 :align center
[[file:images/20230329-212102_screenshot.png]]


* Remuestreo o /bootstrap/

Utilizar técnicas de remuestreo nos permite cuantificar la variabilidad de un estimador estadístico sin necesidad de invocar un régimen asintótico para el procedimiento. Asimismo, nos permite controlar, hasta cierto punto, la variabilidad de nuestros estimadores.$^\dagger$


$^\dagger$: Mas información de esto en el curso de ~EST-24107: Simulación~.

#+REVEAL: split
Por ejemplo, consideremos la situación en donde tenemos una muestra de $n$ observaciones $Z_1, \ldots, Z_n$ las cuales provienen de una distribución con varianza $\sigma^2$. Es fácil demostrar que la varianza de la media $\bar Z_n$ tiene una varianza $\sigma^2/n$.

*** Importante:
:PROPERTIES:
:reveal_background: #00468b
:END:
Esto quiere decir, que podemos 1) generar muestras, 2) promediar y, entonces, reducimos la varianza estimada!

*** Para pensar:
:PROPERTIES:
:reveal_background: #00468b
:END:
Usualmente no tenemos acceso al proceso generador de datos (ya sea $\mathbb{P}_{X,Y}$ ó $\mathbb{P}_X$). ¿Qué estrategia podemos utilizar? 

** /Bootstrap/

Podemos utilizar la muestra $z_1, \ldots, z_n \overset{\mathsf{iid}}{\sim} \pi$ como un /proxy/ de la población de la cual queremos generar observaciones. En este sentido, consideramos que la función de acumulación empírica (~ECDF~, por sus siglas en inglés) es un /buen/ estimador de la función de probabilidad (ó ~CDF~ por sus siglas en inglés)
\begin{align}
\pi[X  \leq x] \approx {\hat \pi}_n[X  \leq x] = \frac1n \sum_{i = 1}^{n} I_{[z_i  \leq x]}\,.
\end{align}

Con mi muestra, entonces, podemos calcular algún estimador de un característica poblacional de interés
\begin{align}
\hat \theta_n = t(z_1, \ldots, z_n)\,.
\end{align}

#+REVEAL: split
Con este procedimiento podemos generar $B$ conjuntos de datos
\begin{align}
z_1^{(b)}, \ldots, z_n^{(b)} \overset{\mathsf{iid}}{\sim} \hat \pi_n\,, \qquad b = 1, \ldots, B\,,
\end{align}
para obtener una colección de estimadores $\hat \theta^{(b)}_n = t(z_1^{(b)}, \ldots, z_n^{(b)})$ y, a través de un promedio, obtener un estimador
\begin{align}
\bar \theta_{B,n}^{(\mathsf{bag})} = \frac1B \sum_{b= 1}^{B} \hat \theta^{(b)}_n \,,
\end{align}
con varianza que se reduce a una tasa $1/B$.

#+BEGIN_NOTES
El muestreo $z_1^{(b)}, \ldots, z_n^{(b)} \overset{\mathsf{iid}}{\sim} \hat \pi_n$ implica tomar muestras *con* reemplazo del conjunto de datos observado. Nota que las remuestras son del mismo tamaño que la muestra original. Es decir, cada remuestra $b$ tiene $n$ observaciones. Como el procedimiento es con reemplazo, esto puede ocasionar que pueda haber algunas observaciones que se repitan en la remuestra.  
#+END_NOTES


** Ejemplo: Suavizadores

La estrategia de remuestreo nos puede ayudar a cuantificar la estabilidad de
ciertos estimadores. Por ejemplo, consideremos los datos que teníamos sobre el
ingreso para un conjunto de 150 observaciones. El interés es construir un
suavizador que relacione ~Edad~ con ~Ingreso~.

#+begin_src R :exports none :results none 
  ## Ejemplo suavizadores ------------------------------------------------------
  library(ISLR)
  set.seed(108727)
  ## Cargamos datos
  data <- tibble(Wage) |> select(year, age, wage, education) |>
    mutate(hi.income = ifelse(wage > 250, 1, 0),
           age = as.numeric(age)) |>
    sample_frac(.05)
#+end_src

#+begin_src R :exports results :results org 
  data |> print(n = 3)
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 150 × 5
   year   age  wage education       hi.income
  <int> <dbl> <dbl> <fct>               <dbl>
1  2003    53  81.6 4. College Grad         0
2  2008    50  82.7 4. College Grad         0
3  2006    35 155.  4. College Grad         0
# … with 147 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_src


#+REVEAL: split
Utilizaremos un suavizador de /splines/ con 15 grados de libertad, ver
[[fig:splines-smooth]].
#+HEADER: :width 900 :height 400 :R-dev-args bg="transparent"
#+begin_src R :file images/splines-bootstrap.jpeg :exports results :results output graphics file
  library(ggformula)
  g1.ssplines <- data |>
    ggplot(aes(age, wage)) +
    geom_point(color = "gray") +
    geom_spline(aes(age, wage, color = "Suavizamiento"),
              df = 15, 
              color = 'red',
              lty = 1,
              show.legend = TRUE) + 
    sin_lineas +
    ## scale_x_continuous(limits = c(10, 80), expand = c(0,0)) +
    xlab("Edad") + ylab("Ingreso") + ggtitle("df = 15")
    coord_cartesian(ylim = c(0, 300))
  g1.ssplines
#+end_src
#+name: fig:splines-smooth
#+caption: Suavizador por /splines/ con 15 grados de libertad. 
#+RESULTS:
[[file:../images/splines-bootstrap.jpeg]]

#+REVEAL: split
A través de remuestreo podemos cuantificar la estabilidad de dicha estimación, ver [[fig:splines-boot]].
#+HEADER: :width 900 :height 400 :R-dev-args bg="transparent"
#+begin_src R :file images/wage-splines-bootstrap.jpeg :exports results :results output graphics file
  library("rsample")
  ajusta_boot <- function(id){
    ## Creo remuestra
    data.boot <- data |>
      slice_sample(prop = 1, replace = TRUE)
    ## Ajusto modelo 
    model <- smooth.spline(y = data.boot$wage, x = data.boot$age, df = 15)
    ## Hago predicciones y las regreso (ojo no extrapola)
    predict(model, newdata = tibble(age = seq(20, 80))) |>
      as_tibble()
  }

  boot.fit <- tibble(id = 1:100) |>
    mutate(resultados = map(id, ajusta_boot))

  g1.ssplines + 
    geom_line(data = unnest(boot.fit, resultados),
              aes(x, y, group = id),
              color = 'lightblue', alpha = .2) +
    geom_spline(aes(age, wage, color = "Suavizamiento"),
                df = 15, 
                color = 'red',
                lty = 1,
                show.legend = TRUE)
#+end_src
#+name: fig:splines-boot
#+caption: Suavizador por /splines/ con 15 grados de libertad, réplicas con remuestreo. 
#+RESULTS:
[[file:../images/wage-splines-bootstrap.jpeg]]

#+REVEAL: split
La estabilidad también la podemos graficar por medio de intervalos de confianza. Ver [[fig:splines-boot-int]].
#+HEADER: :width 900 :height 400 :R-dev-args bg="transparent"
#+begin_src R :file images/wage-splines-bootstrap-intervals.jpeg :exports results :results output graphics file
  boot.fit <- tibble(id = 1:100) |>
    mutate(resultados = map(id, ajusta_boot))

  boot.fit |>
    unnest(resultados) |>
    group_by(x) |>
    summarise(pred.lo = quantile(y, prob = .025),
              pred    = mean(y),
              pred.hi = quantile(y, prob = .975)) |>
    ggplot(aes(x, pred)) +
    geom_ribbon(aes(ymin = pred.lo,
                    ymax = pred.hi),
                fill = "lightblue", alpha = .5) +
    geom_line(color = 'red') +
    geom_point(data = data, aes(age, wage), color = "gray") +
    sin_lineas +
    xlab("Edad") + ylab("Ingreso") + ggtitle("df = 15")
#+end_src
#+name: fig:splines-boot-int
#+caption: Suavizador por /splines/ con 15 grados de libertad, réplicas con remuestreo. 
#+RESULTS:
[[file:../images/wage-splines-bootstrap-intervals.jpeg]]


* /Bootstrapped aggregation: Bagging/

En el contexto de modelado predictivo nos interesa ~estimar la relación~ que
existe entre atributos $x$ y una respuesta de interés $y$ por medio de una
función $f: \mathcal{X} \mapsto \mathcal{Y}$. Dicho estimador, lo denotamos por
$\hat f_n$ haciendo énfasis en que ha sido construido con una muestra de tamaño
$n$. Recordemos que este estimador en el contexto de modelado predictivo es
resultado de un problema de optimización con una función de pérdida adecuada.

#+REVEAL: split
Si utilizamos /bootstrap/, para cada uno de los $B$ conjuntos de entrenamiento
estimamos $\hat f_n^{(b)}$ con $b = 1, \ldots, B$ para poder hacer predicciones
por medio de
\begin{align}
\hat f^{(\mathsf{bag})}_{B,n} (x) = \frac1B \sum_{b = 1}^{B} \hat f_n^{(b)} (x) \,,
\end{align}
esto lo llamamos ~bootstrap aggregation~ o ~bagging~. 

#+REVEAL: split
#+DOWNLOADED: screenshot @ 2023-03-29 11:04:04
#+attr_html: :width 1200 :align center
#+caption: Ilustración esquemática de /bagging/ por medio de árboles de decisión. Tomada de citep:Greenwell2022.
[[file:images/20230329-110404_screenshot.png]]


** En problemas de clasificación

Para problemas de clasificación podemos considerar las predicciones de cada uno
de los modelos $\hat f_n^{(b)}$ y tomar la clase con ~más votos~ dentro del conjunto de
$B$ predictores.

** Error de generalización

- Usando /bootstrap/ entrenamos con cada uno de los conjuntos de datos remuestreados.
- Cada conjunto remuestreado utiliza, en promedio, $2/3$ de los datos originales.
- El conjunto no utilizado lo llamamos ~conjunto fuera de bolsa~ (/out-of-bag/, ~OOB~).
- Podemos obtener predicciones para cada observación $i = 1, \ldots, n$
  cuando se encuentra en algún conjunto ~OOB~. En promedio, tenemos $B/3$ predicciones
  para cada observación, las cuales podemos promediar para obtener la predicción final.
- Esto es un estimador de ~LOO-CV~ utilizando ~bagging~.

** Observaciones

- El estimador $\hat f^{(\mathsf{bag})}_{B,n}$ es un estimador Monte Carlo. ¿De qué?
- El estimador $\hat f^{(\mathsf{bag})}_{B,n} \rightarrow \hat f_n$ con $B\rightarrow \infty$ en cada uno de los puntos a evaluar $x$.
- Cuando los atributos están altamente correlacionados los árboles de decisión
  pueden presentar varianza alta.  =Ventaja:= en esta situación ~bagging~ puede
  suavizar la varianza y reducir el error de generalización.

** /Bagging/, regresión y ~MSE~

- Si estamos en tareas de regresión y medimos el error de generalización por
  medio de pérdida cuadrática obtenemos lo siguiente
  \begin{align}
  \mathbb{E}\left( y - \hat f^*(x) \right)^2 \geq \mathbb{E} \left( y - \mathbb{E} \hat f^*(x) \right)^2\,,
  \end{align}
  donde $\hat f^*$ es una estimación por medio de una remuestra y $\mathbb{E}\hat f^*$ es el valor esperado de las estimaciones de $f$ utilizando remuestras.
- Por lo tanto, /bagging/ podrá disminuir el ~MSE~.

** /Bagging/ y clasificación

- En problemas de clasificación, no tenemos descomposición aditiva de sesgo y varianza. A menos que $\ldots$
- El uso de ~bagging~ puede hacer de un mal clasificador, algo todavía peor. Consideremos el
  caso siguiente.

*** /Bagging/ y clasificadores:
:PROPERTIES:
:reveal_background: #00468b
:END:
Supongamos que tenemos un clasificador binario que asigna $Y = 1$ para todo $x$ con probabilidad $0.4$. ¿Cuál es el la tasa de error de clasificación de este modelo? ¿Cuál sería la tasa de error de clasificación de un consenso con este modelo?

*** /Bagging/ y la sabiduría de las masas:
:PROPERTIES:
:reveal_background: #00468b
:END:
Supongamos que tenemos una colección de clasificadores independientes donde cada
uno tiene una tasa de error de $\varepsilon < 0.5$, y sea
\begin{align}
S_1(x) = \sum_{b = 1}^{B} I[G^{(b)}(x) = 1]\,,
\end{align}
el voto por consenso de que la instancia $x$ pertenezca a la clase 1. Dado que los clasificadores
son independientes entonces
\begin{align}
S_1(x) \sim \mathsf{Binomial}(B, 1- \varepsilon)\,,
\end{align}
donde
\begin{align}
\mathbb{P}(\text{ clasificación correcta }) = \mathbb{P}(S_1 > B/2) \approx 1\,,
\end{align}
con $B$ suficientemente grande.


#+BEGIN_NOTES
El resultado anterior se conoce como ~Sabiduría de las masas~ en donde se asume que cada clasificador es un clasificador ~débil~. Con tasa de error ligeramente menor al azar. Para que el consenso de dichos clasificadores tenga buenos resultados se necesita, además, que los clasificadores sean ~independientes~. 
#+END_NOTES

** Observaciones

- Utilizar ~bagging~ en un problema de clasificación con árboles no es un 
  procedimiento que utilice árboles independientes. Por lo tanto no hay garantía
  de que el consenso mejore el error de clasificación.
- En general para ~bagging~ estamos dispuestos a usar modelos de ~alta varianza~
  puesto que el remuestreo se encarga de ayudarnos a contenerla.


* Aplicación: Misiones de astronautas

Ejemplo tomado de: [[https://juliasilge.com/blog/astronaut-missions-bagging/][Bagging with tidymodels and #TidyTuesday astronaut missions]].
Cargamos la información y exploramos cuál es la nave (/¿spacecraft?/) que mas se utiliza en misiones espaciales.

#+begin_src R :exports none :results none
  ## Aplicación: Misiones de astronautas ---------------------------------------
  astronauts <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-14/astronauts.csv")
#+end_src

#+begin_src R :exports both :results org 
  astronauts |>
    count(in_orbit, sort = TRUE) |>
    print(n = 3)
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 289 × 2
  in_orbit     n
  <chr>    <int>
1 ISS        174
2 Mir         71
3 Salyut 6    24
# … with 286 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_src

#+REVEAL: split
Podemos explorar cómo ha cambiado la duración de las misiones a lo largo del tiempo.

#+HEADER: :width 1200 :height 400 :R-dev-args bg="transparent"
#+begin_src R :file images/astronautas-misiones.jpeg :exports results :results output graphics file
  astronauts |>
    mutate(
      year_of_mission = 10 * (year_of_mission %/% 10),
      year_of_mission = factor(year_of_mission)
    ) |>
    ggplot(aes(year_of_mission, hours_mission,
               fill = year_of_mission, color = year_of_mission
               )) +
    geom_boxplot(alpha = 0.2, size = 1.5, show.legend = FALSE) +
    scale_y_log10() + sin_lineas + 
    labs(x = NULL, y = "Duration of mission in hours")
#+end_src

#+RESULTS:
[[file:../images/astronautas-misiones.jpeg]]

#+begin_src R :exports none :results none
  astronauts_df <- astronauts |>
    select(
      name, mission_title, hours_mission,
      military_civilian, occupation, year_of_mission, in_orbit
    ) |>
    mutate(
      in_orbit = case_when(
        str_detect(in_orbit, "^Salyut") ~ "Salyut",
        str_detect(in_orbit, "^STS") ~ "STS",
        TRUE ~ in_orbit
      ),
      occupation = str_to_lower(occupation)
    ) |>
    filter(hours_mission > 0) |>
    mutate(hours_mission = log(hours_mission)) |>
    na.omit() |>
    select(c(-mission_title, -name))
#+end_src

#+REVEAL: split
*Objetivo*: predecir la duración de una misión espacial en función de algunas características de la misión. 

#+begin_src R :exports results :results org 
  astronauts_df |>
    print(n = 5, width = 75)
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 1,270 × 5
  hours_mission military_civilian occupation year_of_mission in_orbit      
          <dbl> <chr>             <chr>                <dbl> <chr>         
1         0.571 military          pilot                 1961 Vostok 2      
2         3.22  military          pilot                 1961 Vostok 2      
3         1.61  military          pilot                 1962 MA-6          
4         5.36  military          psp                   1998 STS           
5         1.61  military          pilot                 1962 Mercury-Atlas…
# … with 1,265 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_src

** Proceso de modelado

#+begin_src R :exports none :results none
  ### Preprocesamiento -------------------------------------------------------
#+end_src

#+begin_src R :exports code :results none
  set.seed(123)
  astro_split <- initial_split(astronauts_df, strata = hours_mission)
  astro_train <- training(astro_split)
  astro_test <- testing(astro_split)
#+end_src

#+REVEAL: split
#+begin_src R :exports code :results none
  astro_recipe <- recipe(hours_mission ~ ., data = astro_train) |>
    step_other(occupation, in_orbit,
               threshold = 0.005, other = "Other"
               ) |>
    step_dummy(all_nominal_predictors())
#+end_src

#+REVEAL: split
#+begin_src R :exports both :results org 
  astro_wf <- workflow() |>
    add_recipe(astro_recipe)

  astro_wf
#+end_src

#+RESULTS:
#+begin_src org
══ Workflow ════════════════════════════════════════════════════════════════════════
Preprocessor: Recipe
Model: None

── Preprocessor ────────────────────────────────────────────────────────────────────
2 Recipe Steps

• step_other()
• step_dummy()
#+end_src

** Ajuste de /bagging/ con árboles de clasificación 

Especificamos el modelo que utilizaremos

#+begin_src R :exports none :results none
  ### Ajuste de modelo ---------------------------------------------------------
#+end_src


#+begin_src R :exports both :results org 
  library(baguette)

  tree_spec <- bag_tree() |>
    set_engine("rpart", times = 100) |>
    set_mode("regression")

  tree_spec
#+end_src

#+RESULTS:
#+begin_src org
Bagged Decision Tree Model Specification (regression)

Main Arguments:
  cost_complexity = 0
  min_n = 2

Engine-Specific Arguments:
  times = 100

Computational engine: rpart
#+end_src

#+REVEAL: split

Ajustamos el modelo a nuestros de datos de entrenamiento.

#+begin_src R :exports both :results org 
  tree_rs <- astro_wf |>
    add_model(tree_spec) |>
    fit(astro_train)

  tree_rs
#+end_src

#+RESULTS:
#+begin_src org
  == Workflow [trained] =====================================================
  Preprocessor: Recipe
  Model: bag_tree()

  -- Preprocessor -----------------------------------------------------------
  2 Recipe Steps

  - step_other()
  - step_dummy()

  -- Model-------------------------------------------------------------------
  Bagged CART (regression with 100 members)

  Variable importance scores include:

  # A tibble: 13 × 4
  term                             value std.error  used
  <chr>                            <dbl>     <dbl> <int>
  1 year_of_mission                  872.      12.0    100
  2 in_orbit_Other                   592.      27.9    100
  3 in_orbit_STS                     339.      13.3    100
  4 occupation_flight.engineer       233.      13.5    100
  5 in_orbit_Mir                     133.       9.35   100
  6 occupation_pilot                 130.       9.02   100
  7 in_orbit_Salyut                  103.       4.64   100
  8 occupation_msp                    99.4      4.63   100
  9 occupation_other..space.tourist.  44.2      2.24   100
  10 military_civilian_military        39.6      1.96   100
  11 occupation_psp                    22.3      2.57   100
  12 in_orbit_Mir.EP                   18.8      1.57    95
  13 occupation_Other                  17.5      1.17    88
#+end_src

#+REVEAL: split
Realizamos predicciones en nuestro conjunto de prueba para poder reportar capacidad predictiva. 

#+begin_src R :exports both :results org 
  test_rs <- astro_test |>
    bind_cols(predict(tree_rs, astro_test)) |>
    rename(.pred_tree = .pred)

  test_rs |> print(n = 5, width = 73)
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 318 × 6
  hours_mission military_civilian occupation year_of_mi…¹ in_or…² .pred…³
          <dbl> <chr>             <chr>             <dbl> <chr>     <dbl>
1          3.22 military          pilot              1961 Vostok…    1.76
2          1.61 military          pilot              1962 MA-6       3.19
3          5.36 military          psp                1998 STS        5.62
4          6.05 military          pilot              1970 Soyuz 9    5.34
5          5.93 military          commander          1974 Soyuz …    6.08
# … with 313 more rows, and abbreviated variable names ¹​year_of_mission,
#   ²​in_orbit, ³​.pred_tree
# ℹ Use `print(n = ...)` to see more rows
#+end_src

#+REVEAL: split
Por ejemplo, podemos reportar un conjunto de métricas

#+begin_src R :exports both :results org 
  test_rs |>
    metrics(hours_mission, .pred_tree)
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 3 × 3
  .metric .estimator .estimate
  <chr>   <chr>          <dbl>
1 rmse    standard       0.682
2 rsq     standard       0.756
3 mae     standard       0.360
#+end_src

#+REVEAL: split
Podemos jugar con el modelo para tratar de entender la respuesta del modelo a situaciones de interés. 

#+begin_src R :exports both :results org 
  new_astronauts <- crossing(
    in_orbit = fct_inorder(c("ISS", "STS", "Mir", "Other")),
    military_civilian = "civilian",
    occupation = "Other",
    year_of_mission = seq(1960, 2020, by = 10)
  ) |>
    filter(
      !(in_orbit == "ISS" & year_of_mission < 2000),
      !(in_orbit == "Mir" & year_of_mission < 1990),
      !(in_orbit == "STS" & year_of_mission > 2010),
      !(in_orbit == "STS" & year_of_mission < 1980)
    )

  new_astronauts
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 18 × 4
   in_orbit military_civilian occupation year_of_mission
   <fct>    <chr>             <chr>                <dbl>
 1 ISS      civilian          Other                 2000
 2 ISS      civilian          Other                 2010
 3 ISS      civilian          Other                 2020
 4 STS      civilian          Other                 1980
 5 STS      civilian          Other                 1990
 6 STS      civilian          Other                 2000
 7 STS      civilian          Other                 2010
 8 Mir      civilian          Other                 1990
 9 Mir      civilian          Other                 2000
10 Mir      civilian          Other                 2010
11 Mir      civilian          Other                 2020
12 Other    civilian          Other                 1960
13 Other    civilian          Other                 1970
14 Other    civilian          Other                 1980
15 Other    civilian          Other                 1990
16 Other    civilian          Other                 2000
17 Other    civilian          Other                 2010
18 Other    civilian          Other                 2020
#+end_src

#+REVEAL: split
#+HEADER: :width 900 :height 400 :R-dev-args bg="transparent"
#+begin_src R :file images/astronautas-fake-data.jpeg :exports results :results output graphics file
  new_astronauts |>
    bind_cols(predict(tree_rs, new_astronauts)) |>
    ggplot(aes(year_of_mission, .pred, color = in_orbit)) +
    geom_line(size = 1.5, alpha = 0.7) +
    geom_point(size = 2) +
    labs(
      x = NULL, y = "Duration of mission in hours",
      color = NULL, title = "How did the duration of astronauts' missions change over time?",
      subtitle = "Predicted using bagged decision tree model"
    ) + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/astronautas-fake-data.jpeg]]

* Bosques aleatorios

El modelo propuesto de Bosques aleatorios (~RF~ por sus siglas en inglés) ayuda a de-correlacionar un conjunto de árboles.
Para lograr esto seguimos utilizando remuestreo para seleccionar conjuntos de datos de entrenamiento. Al mismo tiempo, con cada conjunto de remuestras, utilizamos un conjunto de $m$ predictores al azar para entrenar. Esto es, utilizamos para cada remuestra, un subconjunto distinto de predictores para entrenar un árbol. 

#+REVEAL: split
Usualmente consideramos $m\approx \sqrt{p}$. Esto permite restringir el espacio de búsqueda y dejar de utilizar consistentemente los mismos predictores en cada remuestra.

** Motivación

Si consideramos la situación donde tenemos $B$ variables $\mathsf{iid}$ cada una con varianza $\sigma^2$  entonces el promedio tendrá varianza igual $\sigma^2/B$. Si las variables son sólo $\mathsf{id}$ (números aleatorios de la misma población) con correlación positiva $\rho$ , entonces el promedio tendrá varianza igual a
\begin{align}
\rho \sigma^2  + \frac{1 - \rho}{B} \sigma^2\,.
\end{align}

#+BEGIN_NOTES
Incluso aunque tomemos un número suficiente de árboles para controlar el segundo término, el primer término no desvanece con $B \rightarrow \infty$. Es por esto que bosques aleatorios busca reducir la correlación entre árboles al permitir que se ajusten a conjuntos aleatorios (en observaciones y predictores) por medio de remuestreo.
#+END_NOTES


** Sobre-ajuste

- El consenso de votos tiende a ser robusto contra sobre-ajustar y si utilizamos una $B$  (el número de árboles) suficientemente grande estabilizamos la variabilidad del error de generalización. 
- Usualmente tenemos problemas de sobre-ajuste cuando el número de predictores es alto y el número de predictores relevantes para la predicción es pequeño.

** Análisis de ajuste

La predicción de un bosque aleatorio se realiza por medio de
\begin{align}
\hat f_{\mathsf{RF}}(x) = \frac1B \sum_{b=1}^{B} \hat f^{(b)}(x) = \frac1B \sum_{b=1}^{B} T\left(x; \Theta(\mathcal{D}_n^{(b)})\right)\,,
\end{align}
donde $T(x; \Theta)$ denota la predicción de un árbol utilizando los parámetros (variables de selección, puntos de corte) $\Theta$. La notación $\Theta(\mathcal{D}_n)$ hace énfasis en que los parámetros que gobiernan el árbol fueron escogidos utilizando el conjunto de datos $\mathcal{D}_n$. El término $\mathcal{D}_n^{(b)}$ hace énfasis en que el conjunto de entrenamiento es una remuestra del conjunto original.

#+REVEAL: split
El predictor tiende a satisfacer la siguiente igualdad (ley de los grandes números, $B \rightarrow \infty$)
\begin{align}
\hat f_{\mathsf{RF}}(x) = \mathbb{E}_{\Theta | \mathcal{D}_n} T\left(x; \Theta(\mathcal{D}_n)\right)\,, 
\end{align}
donde hacemos énfasis en que es un valor esperado condicional en los datos de entrenamiento.

#+REVEAL: split
Nos interesa evaluar el ~error estándar~ de dicho estimador. Lo cual escribimos como 
\begin{align}
\mathsf{SE}\left(\hat f_{\mathsf{RF}}(x)  \right)^2 = \mathbb{V}\left(\hat f_{\mathsf{RF}}(x) \right) = \rho(x) \cdot \sigma^2(x)\,, 
\end{align}
donde:
- $\rho(x)$ es la correlación entre dos árboles
  \begin{align}
  \rho(x) = \mathsf{Corr}\left[ T\left(x; \Theta_i(\mathcal{D}_n)\right), T\left(x; \Theta_j(\mathcal{D}_n)\right)\right]\,.
  \end{align}
- $\sigma^2(x)$ es la varianza de cualquier árbol
  \begin{align}
  \sigma^2(x) = \mathbb{V}\left(T\left(x; \Theta(\mathcal{D}_n)\right)\right)\,.
  \end{align}

* Aplicación: Predicción de árboles con bosques aleatorios         :noexport:

#+begin_src R :exports none :results none  :tangle no
  ## Aplicación: Arboles en San Francisco --------------------------------------
  sf_trees <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-28/sf_trees.csv", show_col_types = FALSE, progress = FALSE)
#+end_src


#+begin_src R :exports none :results none :tangle no
  trees_df <- sf_trees |>
    mutate(
      legal_status = case_when(
        legal_status == "DPW Maintained" ~ legal_status,
        TRUE ~ "Other"
      ),
      plot_size = parse_number(plot_size)
    ) |>
    select(-address)|>
    na.omit() |>
    mutate_if(is.character, factor)
#+end_src

#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/arboles-localizacion.jpeg :exports results :results output graphics file :tangle no
  trees_df |>
    ggplot(aes(longitude, latitude, color = legal_status)) +
    geom_point(size = 0.5, alpha = 0.4) +
    labs(color = NULL) +
  sin_lineas + coord_equal()
#+end_src

#+RESULTS:
[[file:../images/arboles-localizacion.jpeg]]

#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/arboles-cuidadores.jpeg :exports results :results output graphics file :tangle no
trees_df |>
  count(legal_status, caretaker) |>
  add_count(caretaker, wt = n, name = "caretaker_count") |>
  filter(caretaker_count > 50) |>
  group_by(legal_status) |>
  mutate(percent_legal = n / sum(n)) |>
  ggplot(aes(percent_legal, caretaker, fill = legal_status)) +
  geom_col(position = "dodge") +
  labs(
    fill = NULL,
    x = "% of trees in each category"
  ) + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/arboles-cuidadores.jpeg]]

#+begin_src R :exports none :results none :tangle no
  set.seed(108727)
  trees_split <- initial_split(trees_df, strata = legal_status, prop = 1/2)
  trees_train <- training(trees_split)
  trees_test <- testing(trees_split)
#+end_src

#+begin_src R :exports none :results none :tangle no
  tree_rec <- recipe(legal_status ~ ., data = trees_train) |>
    update_role(tree_id, new_role = "ID") |>
    step_other(species, caretaker, threshold = 0.01) |>
    step_other(site_info, threshold = 0.005) |>
    step_dummy(all_nominal(), -all_outcomes()) |>
    step_date(date, features = c("year")) |>
    step_rm(date)
#+end_src

#+begin_src R :exports none :results none :tangle no
  tune_spec <- rand_forest(
    mtry = tune(),
    trees = 1000,
    min_n = tune()
  ) |>
    set_mode("classification") |>
    set_engine("ranger", importance = "permutation")
#+end_src

#+begin_src R :exports none :results none :tangle no
  tune_wf <- workflow() |>
    add_recipe(tree_rec) |>
    add_model(tune_spec)
#+end_src

#+begin_src R :exports none :results none :tangle no
  set.seed(108727)
  trees_folds <- vfold_cv(trees_train, 10)
#+end_src

#+begin_src R :exports code :results org 
  tree_grid <- grid_random(mtry(c(1,35)),
                           min_n(),
                           size = 20)
  tree_grid |> print(n = 5)
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 20 × 2
   mtry min_n
  <int> <int>
1    29     2
2    25     6
3     9    27
4    16    10
5    26    22
# … with 15 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_src

#+begin_src R :exports none :results none :tangle no
  doParallel::registerDoParallel()

  set.seed(108727)
  tune_res <- tune_grid(
    tune_wf,
    grid = tree_grid, 
    resamples = trees_folds,
    control = control_grid(parallel_over = "resamples", verbose = TRUE)
  )
#+end_src

#+HEADER: :width 1200 :height 400 :R-dev-args bg="transparent"
#+begin_src R :file images/arboles-resultados-vc-bosques.jpeg :exports results :results output graphics file :tangle no
  tune_res |>
    collect_metrics() |>
    filter(.metric == "roc_auc") |>
    select(mean, min_n, mtry) |>
    pivot_longer(min_n:mtry,
                 values_to = "value",
                 names_to = "parameter"
                 ) |>
    ggplot(aes(value, mean, color = parameter)) +
    geom_point(show.legend = FALSE) +
    facet_wrap(~parameter, scales = "free_x") +
    labs(x = NULL, y = "AUC") + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/arboles-resultados-vc-bosques.jpeg]]

#+begin_src R :exports code :results none :tangle no
  rf_grid <- grid_regular(
    mtry(range = c(10, 30)),
    min_n(range = c(2, 8)),
    levels = 5
  )
#+end_src

#+begin_src R :exports code :results none  :tangle no
  set.seed(108727)
  regular_res <- tune_grid(
    tune_wf,
    resamples = trees_folds,
    grid = rf_grid,
    control = control_grid(parallel_over = "resamples")
  )
#+end_src

#+HEADER: :width 900 :height 400 :R-dev-args bg="transparent"
#+begin_src R :file images/arboles-vc-zoom-bosques.jpeg :exports results :results output graphics file
  regular_res |>
    collect_metrics() |>
    filter(.metric == "roc_auc") |>
    mutate(min_n = factor(min_n)) |>
    ggplot(aes(mtry, mean, color = min_n)) +
    geom_line(alpha = 0.5, linewidth = 1.5) +
    geom_point() +
    labs(y = "AUC") + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/arboles-vc-zoom-bosques.jpeg]]

#+begin_src R :exports both :results org :tangle no
  best_auc <- select_best(regular_res, "roc_auc")

  final_rf <- finalize_model(
    tune_spec,
    best_auc
  )

  final_rf
#+end_src

#+RESULTS:
#+begin_src org
Random Forest Model Specification (classification)

Main Arguments:
  mtry = 25
  trees = 1000
  min_n = 2

Engine-Specific Arguments:
  importance = permutation

Computational engine: ranger
#+end_src

#+begin_src R :exports code :results org  :tangle no

  final_wf <- workflow() |>
    add_recipe(tree_rec) |>
    add_model(final_rf)

  final_res <- final_wf |>
    last_fit(trees_split)

  final_res |>
    collect_metrics()

#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 2 × 4
  .metric  .estimator .estimate .config             
  <chr>    <chr>          <dbl> <chr>               
1 accuracy binary         0.861 Preprocessor1_Model1
2 roc_auc  binary         0.919 Preprocessor1_Model1
#+end_src


#+HEADER: :width 900 :height 400 :R-dev-args bg="transparent"
#+begin_src R :file images/arboles-bosque-importancia.jpeg :exports results :results output graphics file
  library(vip)

  final_res |>
    extract_fit_engine() |>
    vip() + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/arboles-bosque-importancia.jpeg]]

#+begin_src R :exports results :results org :tangle no
  final_res |>
    collect_predictions() |>
    conf_mat(legal_status, .pred_class)
#+end_src

#+RESULTS:
#+begin_src org
                Truth
Prediction       DPW Maintained Other
  DPW Maintained          14819  1874
  Other                    1017  3152
#+end_src

#+begin_src R :exports results :results org :tangle no
  final_res |>
    collect_predictions() |>
    recall(legal_status, .pred_class)
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 1 × 3
  .metric .estimator .estimate
  <chr>   <chr>          <dbl>
1 recall  binary         0.936
#+end_src



* Aplicación: Predicción de precios IKEA

Ejemplo tomado de:  [[https://juliasilge.com/blog/ikea-prices/][Tune random forests for #TidyTuesday IKEA prices]].

#+begin_src R :exports none :results none
  ## Aplicacion: Precios de IKEA ---------------------------------------------
  ikea <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-11-03/ikea.csv")
#+end_src

#+HEADER: :width 1200 :height 400 :R-dev-args bg="transparent"
#+begin_src R :file images/ikea-precios-exploratorio.jpeg  :exports results :results output graphics file
  ikea |>
    select(`...1`, price, depth:width) |>
    pivot_longer(depth:width, names_to = "dim") |>
    ggplot(aes(value, price, color = dim)) +
    geom_point(alpha = 0.4, show.legend = FALSE) +
    scale_y_log10() +
    facet_wrap(~dim, scales = "free_x") +
    labs(x = NULL) + sin_lineas
#+end_src
#+caption: Relación del precio con las dimensiones del producto.
#+RESULTS:
[[file:../images/ikea-precios-exploratorio.jpeg]]

#+REVEAL: split
Los datos que tenemos disponibles son los siguientes. 
#+begin_src R :exports both :results org 
  ikea_df <- ikea |>
    select(price, name, category, depth, height, width) |>
    mutate(price = log10(price)) |>
    mutate_if(is.character, factor)

  ikea_df |> print(n = 5)
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 3,694 × 6
  price name                  category      depth height width
  <dbl> <fct>                 <fct>         <dbl>  <dbl> <dbl>
1  2.42 FREKVENS              Bar furniture    NA     99    51
2  3.00 NORDVIKEN             Bar furniture    NA    105    80
3  3.32 NORDVIKEN / NORDVIKEN Bar furniture    NA     NA    NA
4  1.84 STIG                  Bar furniture    50    100    60
5  2.35 NORBERG               Bar furniture    60     43    74
# … with 3,689 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_src

** Preparación de datos

#+begin_src R :exports none :results none
  ### Preporocesamiento --------------------------------------------------------
#+end_src

#+begin_src R :exports code :results none 
  set.seed(123)
  ikea_split <- initial_split(ikea_df, strata = price)
  ikea_train <- training(ikea_split)
  ikea_test <- testing(ikea_split)

  set.seed(234)
  ikea_folds <- vfold_cv(ikea_train, strata = price)
#+end_src

#+REVEAL: split
#+begin_src R :exports code :results none 
  library(textrecipes)
  ranger_recipe <-
    recipe(formula = price ~ ., data = ikea_train) |>
    step_other(name, category, threshold = 0.01) |>
    step_clean_levels(name, category) |>
    step_impute_knn(depth, height, width)
#+end_src

** Especificación del modelo

#+begin_src R :exports none :results none
  ### Especificación modelo ----------------------------------------------------
#+end_src


#+begin_src R :exports code :results none 
  ranger_spec <-
    rand_forest(mtry = tune(), min_n = tune(), trees = 1000) |>
    set_mode("regression") |>
    set_engine("ranger")

  ranger_workflow <-
    workflow() |>
    add_recipe(ranger_recipe) |>
    add_model(ranger_spec)
#+end_src

#+REVEAL: split
#+begin_src R :exports code :results none
  all_cores <- parallel::detectCores(logical = TRUE) - 1
  library(doParallel)
  cl <- makePSOCKcluster(all_cores)
  registerDoParallel(cl)
#+end_src


#+begin_src R :exports both :results org
  set.seed(8577)
  system.time(
  ranger_tune <-
    tune_grid(ranger_workflow,
              resamples = ikea_folds,
              grid = 11,
              control = control_grid(
                parallel_over = "resamples",
                verbose = TRUE))
  )
#+end_src

#+RESULTS:
#+begin_src org
   user  system elapsed 
  0.776   0.026  40.034 
#+end_src

#+REVEAL: split
#+begin_src R :exports both :results org 
  show_best(ranger_tune, metric = "rmse")
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 5 × 8
   mtry min_n .metric .estimator  mean     n std_err .config              
  <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                
1     2     4 rmse    standard   0.323    10 0.00602 Preprocessor1_Model10
2     5     6 rmse    standard   0.331    10 0.00562 Preprocessor1_Model06
3     4    10 rmse    standard   0.332    10 0.00570 Preprocessor1_Model05
4     3    18 rmse    standard   0.339    10 0.00569 Preprocessor1_Model01
5     2    21 rmse    standard   0.343    10 0.00561 Preprocessor1_Model08
#+end_src

#+REVEAL: split
#+begin_src R :exports both :results org 
  show_best(ranger_tune, metric = "rsq")
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 5 × 8
   mtry min_n .metric .estimator  mean     n std_err .config              
  <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                
1     2     4 rsq     standard   0.752    10  0.0106 Preprocessor1_Model10
2     5     6 rsq     standard   0.740    10  0.0100 Preprocessor1_Model06
3     4    10 rsq     standard   0.738    10  0.0101 Preprocessor1_Model05
4     3    18 rsq     standard   0.728    10  0.0104 Preprocessor1_Model01
5     2    21 rsq     standard   0.723    10  0.0107 Preprocessor1_Model08
#+end_src

#+REVEAL: split
#+begin_src R :exports both :results org 
  final_rf <- ranger_workflow |>
    finalize_workflow(select_best(ranger_tune))

  final_rf
#+end_src

#+RESULTS:
#+begin_src org
== Workflow ===============================================================
Preprocessor: Recipe
Model: rand_forest()

-- Preprocessor -----------------------------------------------------------
3 Recipe Steps

- step_other()
- step_clean_levels()
- step_impute_knn()

-- Model ------------------------------------------------------------------
Random Forest Model Specification (regression)

Main Arguments:
  mtry = 2
  trees = 1000
  min_n = 4

Computational engine: ranger
#+end_src

#+REVEAL: split
La función de ~last_fit~ nos permite ajustar el modelo con todo el conjunto de entrenamiento y evaluar métricas de desempeño en el conjunto de prueba. 
#+begin_src R :exports both :results org 
  ikea_fit <- last_fit(final_rf, ikea_split)
  ikea_fit |> select(c(-id, -.notes)) |> print(width = 75)
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 1 × 4
  splits             .metrics         .predictions       .workflow 
  <list>             <list>           <list>             <list>    
1 <split [2770/924]> <tibble [2 × 4]> <tibble [924 × 4]> <workflow>
#+end_src

#+REVEAL: split
#+begin_src R :exports both :results org 
  collect_metrics(ikea_fit)
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 2 × 4
  .metric .estimator .estimate .config             
  <chr>   <chr>          <dbl> <chr>               
1 rmse    standard       0.318 Preprocessor1_Model1
2 rsq     standard       0.752 Preprocessor1_Model1
#+end_src

#+REVEAL: split
#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/ikea-predicciones-arboles.jpeg :exports results :results output graphics file
  collect_predictions(ikea_fit) |>
    ggplot(aes(price, .pred)) +
    geom_abline(lty = 2, color = "gray50") +
    geom_point(alpha = 0.5, color = "midnightblue") +
    coord_fixed() + sin_lineas
#+end_src
#+caption: Diagrama de dispersión entre predicciones y datos reales en el conjunto de prueba. 
#+RESULTS:
[[file:../images/ikea-predicciones-arboles.jpeg]]

#+REVEAL: split
Utilizando la librería de ~vip~ podemos explorar cuáles son las variables mas importantes (mas delante hablaremos de esto) del modelo.

#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/ikea-vup-bosque.jpeg :exports results :results output graphics file
  library(vip)

  imp_spec <- ranger_spec |>
    finalize_model(select_best(ranger_tune)) |>
    set_engine("ranger", importance = "permutation")

  workflow() |>
    add_recipe(ranger_recipe) |>
    add_model(imp_spec) |>
    fit(ikea_train) |>
    pull_workflow_fit() |>
    vip(aesthetics = list(alpha = 0.8, fill = "midnightblue")) + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/ikea-vup-bosque.jpeg]]

** Post-procesando el bosque

Lo que queremos es explorar los gráficos de desempeño conforme el tamaño del bosque aumenta. Pero la librería de ~tidymodels~  no nos permite acceso a estos elementos. Lo tenemos que tratar de manera especializada.

#+begin_src R :exports none :results none
  ### Postprocesamiento --------------------------------------------------------
#+end_src


#+begin_src R :exports code :results none
  ranger_prep <- prep(ranger_recipe, training = ikea_train)
  rf_model <- randomForest::randomForest(
                              price ~., bake(ranger_prep, ikea_train),
                              mtry = 2, ntree = 1000, nodesize = 4)
#+end_src

¿Por qué necesitamos la receta de preparación de datos? 

#+REVEAL: split
#+begin_src R :exports code :results none
  collect_forest_predictions <- function(model, data){
    ## Obten predicciones por arbol
    predictions <- predict(model, bake(ranger_prep, data), predict.all = TRUE)
    predictions$individual |>
      ## obten tabla nrows x ncols = nobs x ntrees
      as_tibble() |>
      mutate(observation = 1:nrow(data),
             ## agrega response
             truth = data$price) |>
      ## obten tabla de nrows = nobs x ntrees
      pivot_longer(cols = 1:1000,
                   values_to = ".prediction", names_to = ".tree")  |>
      group_by(observation) |>
      ## reordena los arboles de manera aleatoria
      sample_frac(1, replace = FALSE) |>
      ## calcula prediccion del bosque
      mutate(.estimate = cummean(.prediction),
             .order = 1:n()) |>
      ungroup() |> select(c(-.prediction)) |>
      nest(data = c(observation, truth, .estimate, .tree)) |>
      ## calcula metrica de error
      mutate(results = map(data, function(x) { x |> rmse(truth, .estimate) })) |>
      select(-data)
  }
#+end_src

#+REVEAL: split
#+begin_src R :exports code :results none
  nexp <- 100; set.seed(108)
  predictions_train <- tibble(.expid = 1:nexp) |>
    mutate(.performance = map(## realiza remuestreo de orden de arboles
             .expid,
             ~collect_forest_predictions(rf_model, ikea_train)),
           .type = "training")
  predictions_test <- tibble(.expid = 1:nexp) |>
    mutate(.performance = map(## realiza remuestreo de orden de arboles
             .expid,
             ~collect_forest_predictions(rf_model, ikea_test)),
           .type = "testing")
#+end_src

#+REVEAL: split
#+HEADER: :width 1200 :height 400 :R-dev-args bg="transparent"
#+begin_src R :file images/ikea-bosque-complejidad.jpeg :exports results :results output graphics file
  original_results <- predictions_train |>
    rbind(predictions_test) |>
    unnest(.performance) |> unnest(results) |>
    group_by(.type, .order) |>
    summarise(.error = mean(.estimate),
              .inf = quantile(.estimate, .05),
              .sup = quantile(.estimate, .95),
              .groups = "drop")

  original_results |>
    ggplot(aes(.order, .error, fill = .type, group = .type, color = .type)) +
    geom_ribbon(aes(ymin = .inf, ymax = .sup), alpha = .2, color = "white") + 
    geom_line() + sin_lineas +  scale_x_log10()
#+end_src
#+caption: Error predictivo utilizando bosque aleatorio.
#+RESULTS:
[[file:../images/ikea-bosque-complejidad.jpeg]]

#+begin_src R :exports none :results none :tangle no :eval never
  predictions_train <- collect_forest_predictions(rf_model, ikea_train)
  predictions_test  <- collect_forest_predictions(rf_model, ikea_test)
#+end_src

#+HEADER: :width 1200 :height 400 :R-dev-args bg="transparent"
#+begin_src R :file images/ikea-bosque-complejidad.jpeg :exports results :results output graphics file :tangle no :eval never
  predictions_train |> unnest(results) |>
    mutate(.tree_id = 1:1000,
           .train = .estimate,
           .test  = unnest(predictions_test, results)$.estimate) |>
    select(c(.tree_id, .train, .test)) |>
    pivot_longer(cols = 2:3, names_to = "data", values_to = ".error") |>
    ggplot(aes(.tree_id, .error, .group = data, color = data)) +
    geom_line() + sin_lineas + scale_x_log10()
#+end_src


** Post-procesamiento predictivo

¿Y si queremos encontrar un subconjunto de árboles del bosque para mejorar las predicciones en conjuntos de datos nuevos? ¿Qué estrategia hemos visto que nos puede ayudar con este objetivo?

#+begin_src R :exports none :results none
  ### Quema de bosque ---------------------------------------------------------- 
#+end_src

#+begin_src R :exports code :results none
  predictions <- predict(rf_model, bake(ranger_prep, ikea_train), predict.all = TRUE)
#+end_src

#+begin_src R :exports none :results none
  trees_train  <- predictions$individual |>
    as_tibble() |>
    mutate(price = ikea_train$price)
#+end_src

#+begin_src R :exports none :results none
  predictions <- predict(rf_model, bake(ranger_prep, ikea_test), predict.all = TRUE)
  trees_test  <- predictions$individual |>
    as_tibble() |>
    mutate(price = ikea_test$price)
#+end_src

#+begin_src R :exports none :results none
  trees_train <- trees_test
#+end_src

#+begin_src R :exports both :results org 
  trees_train |> print(n = 3, width = 75)
  #+end_src

#+RESULTS:
#+begin_src org
# A tibble: 924 × 1,001
     V1    V2    V3    V4    V5    V6    V7    V8    V9   V10   V11   V12
  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
1  2.75  2.18  2.69  3.22  2.78  2.43  2.58  1.84  3.16  2.12  2.69  2.42
2  2.47  2.11  2.44  2.06  2.87  2.80  2.32  2.70  2.67  1.40  2.67  2.54
3  2.11  2.11  2.11  2.06  2.29  2.14  2.15  2.18  2.20  2.11  2.42  2.14
# … with 921 more rows, and 989 more variables: V13 <dbl>, V14 <dbl>,
#   V15 <dbl>, V16 <dbl>, V17 <dbl>, V18 <dbl>, V19 <dbl>, V20 <dbl>,
#   V21 <dbl>, V22 <dbl>, V23 <dbl>, V24 <dbl>, V25 <dbl>, V26 <dbl>,
#   V27 <dbl>, V28 <dbl>, V29 <dbl>, V30 <dbl>, V31 <dbl>, V32 <dbl>,
#   V33 <dbl>, V34 <dbl>, V35 <dbl>, V36 <dbl>, V37 <dbl>, V38 <dbl>,
#   V39 <dbl>, V40 <dbl>, V41 <dbl>, V42 <dbl>, V43 <dbl>, V44 <dbl>,
#   V45 <dbl>, V46 <dbl>, V47 <dbl>, V48 <dbl>, V49 <dbl>, V50 <dbl>, …
# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names
#+end_src

#+REVEAL: split
#+begin_src R :exports code :results none
  lasso_spec <- linear_reg(penalty = tune(), mixture = 1) |> 
    set_engine("glmnet") |>
    set_mode("regression")
#+end_src

#+begin_src R :exports code :results none 
  lasso_rec <- recipe(price ~ ., data = trees_train)
#+end_src

#+begin_src R :exports code :results none 
  set.seed(108727)
  forest_boot <- vfold_cv(trees_train, v = 10)
#+end_src

#+REVEAL: split
#+begin_src R :exports code :results none
  lasso_wf <- workflow() |>
    add_recipe(lasso_rec) |> 
    add_model(lasso_spec)

  lasso_grid <- lasso_wf |>
    tune_grid(
      resamples = forest_boot,
      grid = 50,
      control = control_grid(verbose = FALSE)
    )
#+end_src

#+REVEAL: split
#+begin_src R :exports both :results org 
  lasso_grid |>
    collect_metrics() |>
    print(n = 3, width = 75)
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 100 × 7
   penalty .metric .estimator  mean     n std_err .config              
     <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                
1 1.26e-10 rmse    standard   0.312    10  0.0137 Preprocessor1_Model01
2 1.26e-10 rsq     standard   0.762    10  0.0105 Preprocessor1_Model01
3 1.90e-10 rmse    standard   0.312    10  0.0137 Preprocessor1_Model02
# … with 97 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_src

#+REVEAL: split
#+begin_src R :exports code :results none 
  lowest_rmse <- lasso_grid |>
    select_best("rmse")

  final_lasso <- finalize_workflow(
    lasso_wf,
    lowest_rmse
  )
#+end_src

#+REVEAL: split
#+HEADER: :width 700 :height 900 :R-dev-args bg="transparent"
#+begin_src R :file images/forest-lasso-deforest.jpeg :exports results :results output graphics file :eval never :tangle no
  library(vip)

  final_lasso |>
    fit(trees_train) |>
    pull_workflow_fit() |>
    vi(lambda = lowest_rmse$penalty) |>
    mutate(
      Importance = abs(Importance),
      Variable = fct_reorder(Variable, Importance)
    ) |>
    head(100) |>
    ggplot(aes(x = Importance, y = Variable, fill = Sign)) +
    geom_col() +
    scale_x_continuous(expand = c(0, 0)) +
    labs(y = NULL) + sin_lineas
#+end_src

#+begin_src R :exports both :results org 
  active_trees <- final_lasso |>
    fit(trees_train) |>
    broom::tidy() |>
    filter(estimate != 0) |>
    mutate(.tree = term, beta = estimate) |>
    select(c(.tree, beta)) 

  active_trees |> print(n = 5)
#+end_src

#+RESULTS:
#+begin_src org
# A tibble: 65 × 2
  .tree           beta
  <chr>          <dbl>
1 (Intercept) -0.0356 
2 V7           0.0471 
3 V13          0.0344 
4 V17          0.0502 
5 V27          0.00622
# … with 60 more rows
# ℹ Use `print(n = ...)` to see more rows
#+end_src

#+REVEAL: split
#+begin_src R :exports code :results none
  collect_dforest_predictions <- function(model, data, active_trees){
    intercept <- active_trees$beta[1]
    predictions <- predict(model, bake(ranger_prep, data), predict.all = TRUE)
    predictions$individual |>
      as_tibble() |>
      mutate(observation = 1:nrow(data),
             truth = data$price) |>
      pivot_longer(cols = 1:1000,
                   values_to = ".prediction", names_to = ".tree") |>
      right_join(active_trees |> filter(.tree != "(Intercept)"), by = ".tree") |>
      filter(complete.cases(beta)) |>
      group_by(observation) |>
      sample_frac(1, replace = FALSE) |>
      mutate(.estimate = intercept + cumsum(beta * .prediction),
             .order = 1:n()) |>
      ungroup() |> select(c(-.prediction, -beta)) |>
      nest(data = c(observation, truth, .estimate, .tree)) |>
      mutate(results = map(data, function(x) { x |> rmse(truth, .estimate) })) |>
      select(-data)
  }
#+end_src


#+begin_src R :exports none :results none :tangle no :eval never
  collect_dforest_predictions <- function(model, data, active_trees){
    intercept <- active_trees$beta[1]

    predictions <- predict(model, bake(ranger_prep, data), predict.all = TRUE)
    predictions$individual |>
      as_tibble() |>
      mutate(observation = 1:nrow(data),
             truth = data$price) |>
      pivot_longer(cols = 1:1000,
                   values_to = ".prediction", names_to = ".tree") |>
      right_join(active_trees |> filter(.tree != "(Intercept)"), by = ".tree") |>
      filter(complete.cases(beta)) |>
      group_by(observation) |>
      arrange(desc(abs(beta))) |>
      mutate(.estimate = intercept + cumsum(beta * .prediction)) |>
      ungroup() |> select(c(-.prediction, -beta)) |>
      nest(data = c(observation, truth, .estimate)) |>
      mutate(results = map(data, function(x) { x |> rmse(truth, .estimate) }))
  }
#+end_src


#+begin_src R :exports code :results none  :tangle no :eval never
  dpredictions_train <- collect_dforest_predictions(rf_model, ikea_train, active_trees)
  dpredictions_test  <- collect_dforest_predictions(rf_model, ikea_test, active_trees)
#+end_src

#+REVEAL: split
#+begin_src R :exports code :results none
  nexp <- 100; set.seed(108)
  dpredictions_train <- tibble(.expid = 1:nexp) |>
    mutate(.performance = map(## realiza remuestreo de orden de arboles
             .expid,
             ~collect_dforest_predictions(rf_model, ikea_train, active_trees)),
           .type = "dtraining")
  dpredictions_test <- tibble(.expid = 1:nexp) |>
    mutate(.performance = map(## realiza remuestreo de orden de arboles
             .expid,
             ~collect_dforest_predictions(rf_model, ikea_test, active_trees)),
           .type = "dtesting")
#+end_src

#+REVEAL: split
#+HEADER: :width 1200 :height 400 :R-dev-args bg="transparent"
#+begin_src R :file images/ikea-bosque-lasso-complejidad.jpeg :exports results :results output graphics file
  deforest_results <- dpredictions_train |>
    rbind(dpredictions_test) |>
    unnest(.performance) |> unnest(results) |>
    group_by(.type, .order) |>
    summarise(.error = mean(.estimate),
              .inf = quantile(.estimate, .05),
              .sup = quantile(.estimate, .95),
              .groups = "drop")

  deforest_results |>
    ggplot(aes(.order, .error, fill = .type, group = .type, color = .type)) +
    geom_ribbon(aes(ymin = .inf, ymax = .sup), alpha = .2, color = "white") + 
    geom_line() + sin_lineas +  scale_x_log10()
#+end_src
#+caption: Error predictivo utilizando bosque aleatorio.
#+RESULTS:
[[file:../images/ikea-bosque-lasso-complejidad.jpeg]]

#+REVEAL: split
#+HEADER: :width 1200 :height 400 :R-dev-args bg="transparent"
#+begin_src R :file images/ikea-bosque-lasso-complejidad-conjunto.jpeg :exports results :results output graphics file
  original_results |>
    rbind(deforest_results) |>
    ggplot(aes(.order, .error, fill = .type, group = .type, color = .type)) +
    geom_ribbon(aes(ymin = .inf, ymax = .sup), alpha = .2, color = "white") + 
    geom_line() + sin_lineas +  scale_x_log10() + scale_y_log10() 
    ## coord_cartesian(ylim = c(0.1, 1)) 
#+end_src

#+RESULTS:
[[file:../images/ikea-bosque-lasso-complejidad-conjunto.jpeg]]

* Conclusiones

- Los bosques aleatorios son uno de los métodos más generales de predicción.
- Son fáciles de entrenar, usualmente ajustando dos parámetros por validación cruzada.
- Heredan ventajas de los árboles. Por ejemplo, las predicciones siempre se encuentran en el rango de las observaciones.
- Pueden ser lentos en predicción.
- Tienen capacidad de extrapolación limitada. 

bibliographystyle:abbrvnat
bibliography:references.bib
